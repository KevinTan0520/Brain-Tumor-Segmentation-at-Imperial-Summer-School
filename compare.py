import torch
import torch.nn as nn
import torch.nn.functional as F
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
# import cv2  # ç§»é™¤cv2ä¾èµ–
from PIL import Image
import argparse
import os
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•å¹¶è®¾ç½®ä¸ºå·¥ä½œç›®å½•
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
os.chdir(CURRENT_DIR)
print(f"Current working directory set to: {CURRENT_DIR}")

class UNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512]):
        super(UNet, self).__init__()
        self.downs = nn.ModuleList()
        self.ups = nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # ä¸‹é‡‡æ ·è·¯å¾„
        for feature in features:
            self.downs.append(self.double_conv(in_channels, feature))
            in_channels = feature
        
        # ä¸Šé‡‡æ ·è·¯å¾„
        for feature in reversed(features):
            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))
            self.ups.append(self.double_conv(feature*2, feature))
        
        # ç“¶é¢ˆå±‚
        self.bottleneck = self.double_conv(features[-1], features[-1]*2)
        
        # æœ€ç»ˆåˆ†ç±»å±‚
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)
    
    def double_conv(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        skip_connections = []
        
        # ä¸‹é‡‡æ ·
        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)
        
        # ç“¶é¢ˆå±‚
        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]
        
        # ä¸Šé‡‡æ ·
        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)
            skip_connection = skip_connections[idx//2]
            
            # å¤„ç†å°ºå¯¸ä¸åŒ¹é…
            if x.shape != skip_connection.shape:
                x = F.interpolate(x, size=skip_connection.shape[2:])
            
            concat_skip = torch.cat((skip_connection, x), dim=1)
            x = self.ups[idx+1](concat_skip)
        
        return torch.sigmoid(self.final_conv(x))

def load_model(model_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ - å…¼å®¹æ–°æ—§æ ¼å¼å’ŒPyTorchç‰ˆæœ¬"""
    # ç¡®ä¿torchæ¨¡å—å¯ç”¨
    import torch as torch_module
    
    if not os.path.isabs(model_path):
        model_path = os.path.join(CURRENT_DIR, model_path)
    
    print(f"Loading model from: {model_path}")
    print(f"PyTorch version: {torch_module.__version__}")
    
    model = UNet().to(device)
    
    try:
        # æ–¹æ³•1: é¦–å…ˆå°è¯•å®‰å…¨åŠ è½½ï¼ˆä»…æƒé‡ï¼‰- é€‚ç”¨äºPyTorch 2.6+
        print("Attempting safe loading (weights_only=True)...")
        checkpoint = torch_module.load(model_path, map_location=device, weights_only=True)
        model.load_state_dict(checkpoint)
        print("âœ“ Model loaded successfully with weights_only=True")
        
    except Exception as e1:
        print(f"Safe loading failed: {e1}")
        
        try:
            # æ–¹æ³•2: å°è¯•åŠ è½½å®Œæ•´æ£€æŸ¥ç‚¹ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
            print("Attempting full checkpoint loading...")
            checkpoint = torch_module.load(model_path, map_location=device, weights_only=False)
            
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    # æ–°æ ¼å¼ï¼šåŒ…å«å®Œæ•´è®­ç»ƒä¿¡æ¯çš„æ£€æŸ¥ç‚¹
                    model.load_state_dict(checkpoint['model_state_dict'])
                    print("âœ“ Model loaded from checkpoint dict")
                    
                    # æ‰“å°è®­ç»ƒä¿¡æ¯
                    if 'best_dice' in checkpoint:
                        print(f"  â†’ Model's best validation Dice: {checkpoint['best_dice']:.4f}")
                    if 'epoch' in checkpoint:
                        print(f"  â†’ Model was trained for {checkpoint['epoch']} epochs")
                    if 'early_stopping_info' in checkpoint:
                        es_info = checkpoint['early_stopping_info']
                        if es_info.get('triggered', False):
                            print(f"  â†’ Training stopped early at epoch {es_info.get('best_epoch', 'N/A')}")
                        else:
                            print("  â†’ Training completed without early stopping")
                
                else:
                    # ç›´æ¥æ˜¯state_dictæ ¼å¼
                    model.load_state_dict(checkpoint)
                    print("âœ“ Model loaded as direct state_dict")
            else:
                # æ—§æ ¼å¼ï¼šç›´æ¥åŠ è½½
                model.load_state_dict(checkpoint)
                print("âœ“ Model loaded directly")
                
        except Exception as e2:
            print(f"Standard loading failed: {e2}")
            
            try:
                # æ–¹æ³•3: ä½¿ç”¨å®‰å…¨å…¨å±€å¯¹è±¡ä¸Šä¸‹æ–‡
                print("Attempting loading with safe globals...")
                # æ˜ç¡®å¯¼å…¥torch.serialization
                import torch.serialization as torch_serialization
                
                with torch_serialization.safe_globals([
                    'numpy.core.multiarray.scalar',
                    'numpy.dtype', 
                    'numpy.ndarray',
                    'collections.OrderedDict',
                    'builtins.dict',
                    'builtins.int',
                    'builtins.float',
                    'builtins.bool'
                ]):
                    checkpoint = torch_module.load(model_path, map_location=device, weights_only=True)
                    
                    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                        model.load_state_dict(checkpoint['model_state_dict'])
                        print("âœ“ Model loaded with safe globals from checkpoint")
                    else:
                        model.load_state_dict(checkpoint)
                        print("âœ“ Model loaded with safe globals directly")
                        
            except Exception as e3:
                # æ–¹æ³•4: æœ€åçš„å°è¯• - å®Œå…¨ä¸å®‰å…¨åŠ è½½ï¼ˆä»…é™å¯ä¿¡æºï¼‰
                print(f"Safe globals loading failed: {e3}")
                print("âš ï¸  Attempting unsafe loading (use only for trusted models)...")
                
                try:
                    # å®Œå…¨ç¦ç”¨å®‰å…¨æ£€æŸ¥ï¼ˆå±é™©ï¼Œä»…é™å¯ä¿¡æ¨¡å‹ï¼‰
                    checkpoint = torch_module.load(model_path, map_location=device, weights_only=False)
                    
                    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                        model.load_state_dict(checkpoint['model_state_dict'])
                        print("âœ“ Model loaded via unsafe method from checkpoint")
                    else:
                        model.load_state_dict(checkpoint)
                        print("âœ“ Model loaded via unsafe method directly")
                        
                except Exception as e4:
                    print(f"All loading methods failed!")
                    print(f"Final error: {e4}")
                    print(f"Original errors: {e1}, {e2}, {e3}")
                    
                    # æä¾›è°ƒè¯•ä¿¡æ¯
                    print("\nğŸ” Debugging information:")
                    try:
                        checkpoint = torch_module.load(model_path, map_location='cpu', weights_only=False)
                        print(f"  Checkpoint type: {type(checkpoint)}")
                        if isinstance(checkpoint, dict):
                            print(f"  Checkpoint keys: {list(checkpoint.keys())}")
                            
                            # æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
                            for key, value in checkpoint.items():
                                if hasattr(value, 'shape'):
                                    print(f"    {key}: tensor with shape {value.shape}")
                                elif isinstance(value, dict):
                                    print(f"    {key}: dict with keys {list(value.keys())}")
                                else:
                                    print(f"    {key}: {type(value)} - {str(value)[:100]}...")
                                    
                    except Exception as debug_e:
                        print(f"  Cannot inspect checkpoint: {debug_e}")
                    
                    raise RuntimeError(f"Unable to load model from {model_path}. Please check the file format and PyTorch version compatibility.")
    
    model.eval()
    print(f"âœ“ Model set to evaluation mode")
    return model

def preprocess_image(image_slice):
    """é¢„å¤„ç†å›¾åƒåˆ‡ç‰‡"""
    # æ”¹è¿›çš„å½’ä¸€åŒ–ï¼šä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
    if image_slice.std() > 1e-8:
        image_slice = (image_slice - image_slice.mean()) / image_slice.std()
    else:
        image_slice = image_slice - image_slice.mean()
    
    # ç¡®ä¿æ•°å€¼èŒƒå›´åˆç†ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    image_slice = np.clip(image_slice, -5, 5)
    
    # è½¬æ¢ä¸ºtensorå¹¶æ·»åŠ batchå’Œchannelç»´åº¦
    image_tensor = torch.FloatTensor(image_slice).unsqueeze(0).unsqueeze(0)
    return image_tensor

def postprocess_mask(mask, threshold=0.5):
    """åå¤„ç†åˆ†å‰²æ©ç """
    mask = mask.squeeze().cpu().numpy()
    binary_mask = (mask > threshold).astype(np.uint8)
    return binary_mask

def calculate_metrics(pred_mask, true_mask):
    """è®¡ç®—åˆ†å‰²æŒ‡æ ‡"""
    # å±•å¹³æ•°ç»„
    pred_flat = pred_mask.flatten()
    true_flat = true_mask.flatten()
    
    # ç¡®ä¿æ˜¯äºŒå€¼
    pred_flat = (pred_flat > 0).astype(int)
    true_flat = (true_flat > 0).astype(int)
    
    # è®¡ç®—å„ç§æŒ‡æ ‡
    metrics = {}
    
    # åŸºæœ¬åˆ†ç±»æŒ‡æ ‡
    metrics['accuracy'] = accuracy_score(true_flat, pred_flat)
    metrics['precision'] = precision_score(true_flat, pred_flat, zero_division=0)
    metrics['recall'] = recall_score(true_flat, pred_flat, zero_division=0)
    metrics['f1_score'] = f1_score(true_flat, pred_flat, zero_division=0)
    
    # IoU (Intersection over Union) / Jaccard Index
    metrics['iou'] = jaccard_score(true_flat, pred_flat, zero_division=0)
    
    # Diceç³»æ•°
    intersection = np.sum(pred_flat * true_flat)
    dice = (2. * intersection) / (np.sum(pred_flat) + np.sum(true_flat) + 1e-8)
    metrics['dice'] = dice
    
    # Specificity (True Negative Rate)
    tn = np.sum((1 - pred_flat) * (1 - true_flat))
    fp = np.sum(pred_flat * (1 - true_flat))
    specificity = tn / (tn + fp + 1e-8)
    metrics['specificity'] = specificity
    
    # ä½“ç§¯ç›¸å…³æŒ‡æ ‡
    pred_volume = np.sum(pred_flat)
    true_volume = np.sum(true_flat)
    
    # ä½“ç§¯è¯¯å·®
    volume_error = abs(pred_volume - true_volume) / (true_volume + 1e-8)
    metrics['volume_error'] = volume_error
    
    # ç›¸å¯¹ä½“ç§¯å·®å¼‚
    relative_volume_diff = (pred_volume - true_volume) / (true_volume + 1e-8)
    metrics['relative_volume_diff'] = relative_volume_diff
    
    return metrics

def overlay_mask_on_image(image, mask, color=(1.0, 0.0, 0.0), alpha=0.5):
    """åœ¨å›¾åƒä¸Šå åŠ çº¢è‰²è‚¿ç˜¤æ©ç  - ä½¿ç”¨numpyæ›¿ä»£cv2"""
    # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
    if len(image.shape) == 2:
        # ç°åº¦å›¾è½¬RGB
        image_rgb = np.stack([image, image, image], axis=-1)
    else:
        image_rgb = image.copy()
    
    # åˆ›å»ºçº¢è‰²æ©ç 
    colored_mask = np.zeros_like(image_rgb)
    colored_mask[mask == 1] = color
    
    # å åŠ æ©ç 
    result = image_rgb * (1 - alpha) + colored_mask * alpha
    result = np.clip(result, 0, 1)  # ç¡®ä¿å€¼åœ¨[0,1]èŒƒå›´å†…
    return result

def overlay_comparison_masks(image, pred_mask, true_mask, alpha=0.5):
    """åœ¨å›¾åƒä¸Šå åŠ é¢„æµ‹å’ŒçœŸå®æ©ç çš„æ¯”è¾ƒ"""
    # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
    if len(image.shape) == 2:
        image_rgb = np.stack([image, image, image], axis=-1)
    else:
        image_rgb = image.copy()
    
    # åˆ›å»ºæ¯”è¾ƒæ©ç 
    colored_mask = np.zeros_like(image_rgb)
    
    # True Positive: ç»¿è‰² (é¢„æµ‹å¯¹çš„è‚¿ç˜¤åŒºåŸŸ)
    tp_mask = (pred_mask == 1) & (true_mask == 1)
    colored_mask[tp_mask] = (0, 1.0, 0)  # ç»¿è‰²
    
    # False Positive: çº¢è‰² (è¯¯æ£€çš„è‚¿ç˜¤åŒºåŸŸ)
    fp_mask = (pred_mask == 1) & (true_mask == 0)
    colored_mask[fp_mask] = (1.0, 0, 0)  # çº¢è‰²
    
    # False Negative: è“è‰² (æ¼æ£€çš„è‚¿ç˜¤åŒºåŸŸ)
    fn_mask = (pred_mask == 0) & (true_mask == 1)
    colored_mask[fn_mask] = (0, 0, 1.0)  # è“è‰²
    
    # å åŠ æ©ç 
    result = image_rgb * (1 - alpha) + colored_mask * alpha
    result = np.clip(result, 0, 1)
    return result

def test_on_nifti_file_with_ground_truth(model, fla_path, seg_path, device, output_dir='compare_results'):
    """å¯¹NIfTIæ–‡ä»¶è¿›è¡Œæµ‹è¯•å¹¶è®¡ç®—å‡†ç¡®åº¦æŒ‡æ ‡ï¼ˆéœ€è¦ground truthï¼‰"""
    # å¦‚æœè¾“å…¥è·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œåˆ™åŸºäºå½“å‰ç›®å½•æ„å»ºè·¯å¾„
    if not os.path.isabs(fla_path):
        fla_path = os.path.join(CURRENT_DIR, fla_path)
    if not os.path.isabs(seg_path):
        seg_path = os.path.join(CURRENT_DIR, seg_path)
    
    # å¦‚æœè¾“å‡ºç›®å½•ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œåˆ™åŸºäºå½“å‰ç›®å½•æ„å»ºè·¯å¾„
    if not os.path.isabs(output_dir):
        output_dir = os.path.join(CURRENT_DIR, output_dir)
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    print(f"Loading NIfTI files from: {fla_path} and {seg_path}")
    print(f"Output directory: {output_dir}")
    
    # åŠ è½½NIfTIæ–‡ä»¶
    fla_img = nib.load(fla_path)
    seg_img = nib.load(seg_path)
    fla_data = fla_img.get_fdata()
    seg_data = seg_img.get_fdata()
    
    patient_id = os.path.basename(fla_path).replace('_fla.nii.gz', '')
    
    print(f"Processing patient: {patient_id}")
    print(f"Image shape: {fla_data.shape}")
    print(f"Segmentation shape: {seg_data.shape}")
    
    # å¯¹æ‰€æœ‰åˆ‡ç‰‡è¿›è¡Œé¢„æµ‹
    num_slices = fla_data.shape[2]
    predictions = []
    ground_truths = []
    all_metrics = []
    
    print("Processing slices...")
    with torch.no_grad():
        for slice_idx in range(num_slices):
            if (slice_idx + 1) % 20 == 0:
                print(f"  Processed {slice_idx + 1}/{num_slices} slices")
            
            # è·å–åˆ‡ç‰‡
            image_slice = fla_data[:, :, slice_idx]
            true_mask = seg_data[:, :, slice_idx]
            true_mask = (true_mask > 0).astype(np.uint8)
            
            # è·³è¿‡ç©ºåˆ‡ç‰‡
            if image_slice.sum() == 0:
                predictions.append(np.zeros_like(image_slice))
                ground_truths.append(true_mask)
                continue
            
            # é¢„å¤„ç†ï¼ˆä½¿ç”¨æ”¹è¿›çš„é¢„å¤„ç†æ–¹æ³•ï¼‰
            image_tensor = preprocess_image(image_slice).to(device)
            
            # é¢„æµ‹
            pred_mask = model(image_tensor)
            binary_mask = postprocess_mask(pred_mask)
            
            predictions.append(binary_mask)
            ground_truths.append(true_mask)
            
            # è®¡ç®—å½“å‰åˆ‡ç‰‡çš„æŒ‡æ ‡
            if true_mask.sum() > 0 or binary_mask.sum() > 0:  # åªå¯¹æœ‰è‚¿ç˜¤æˆ–æœ‰é¢„æµ‹çš„åˆ‡ç‰‡è®¡ç®—æŒ‡æ ‡
                slice_metrics = calculate_metrics(binary_mask, true_mask)
                slice_metrics['slice_idx'] = slice_idx
                all_metrics.append(slice_metrics)
            
            # ä¿å­˜ä¸€äº›ç¤ºä¾‹åˆ‡ç‰‡ï¼ˆåŒ…å«æ¯”è¾ƒï¼‰
            if slice_idx % 10 == 0 and (binary_mask.sum() > 0 or true_mask.sum() > 0):
                # å½’ä¸€åŒ–å›¾åƒç”¨äºæ˜¾ç¤º
                display_image = (image_slice - image_slice.min()) / (image_slice.max() - image_slice.min() + 1e-8)
                
                # åˆ›å»ºæ¯”è¾ƒå›¾åƒ
                comparison_image = overlay_comparison_masks(display_image, binary_mask, true_mask)
                overlay_image = overlay_mask_on_image(display_image, binary_mask)
                true_overlay = overlay_mask_on_image(display_image, true_mask, color=(0, 1.0, 0))
                
                # ä¿å­˜ç»“æœ
                plt.figure(figsize=(20, 8))
                
                plt.subplot(2, 3, 1)
                plt.imshow(display_image, cmap='gray')
                plt.title(f'Original Slice {slice_idx}')
                plt.axis('off')
                
                plt.subplot(2, 3, 2)
                plt.imshow(true_mask, cmap='Greens')
                plt.title('Ground Truth')
                plt.axis('off')
                
                plt.subplot(2, 3, 3)
                plt.imshow(binary_mask, cmap='Reds')
                plt.title('Prediction')
                plt.axis('off')
                
                plt.subplot(2, 3, 4)
                plt.imshow(true_overlay)
                plt.title('GT Overlay (Green)')
                plt.axis('off')
                
                plt.subplot(2, 3, 5)
                plt.imshow(overlay_image)
                plt.title('Pred Overlay (Red)')
                plt.axis('off')
                
                plt.subplot(2, 3, 6)
                plt.imshow(comparison_image)
                plt.title('Comparison (TP:Green, FP:Red, FN:Blue)')
                plt.axis('off')
                
                plt.tight_layout()
                plt.savefig(f'{output_dir}/{patient_id}_comparison_slice_{slice_idx:03d}.png', 
                           dpi=150, bbox_inches='tight')
                plt.close()
    
    # è®¡ç®—æ•´ä½“æŒ‡æ ‡
    all_predictions = np.concatenate([p.flatten() for p in predictions])
    all_ground_truths = np.concatenate([g.flatten() for g in ground_truths])
    
    overall_metrics = calculate_metrics(all_predictions, all_ground_truths)
    
    # è®¡ç®—åˆ‡ç‰‡çº§åˆ«çš„å¹³å‡æŒ‡æ ‡
    avg_metrics = {}
    if all_metrics:
        for key in all_metrics[0].keys():
            if key != 'slice_idx':
                avg_metrics[f'avg_{key}'] = np.mean([m[key] for m in all_metrics])
                avg_metrics[f'std_{key}'] = np.std([m[key] for m in all_metrics])
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    print(f"EVALUATION RESULTS FOR PATIENT: {patient_id}")
    print("="*60)
    
    print("\nOVERALL METRICS (å…¨ä½“ç´ çº§åˆ«):")
    print(f"Accuracy:           {overall_metrics['accuracy']:.4f}")
    print(f"Dice Coefficient:   {overall_metrics['dice']:.4f}")
    print(f"IoU (Jaccard):      {overall_metrics['iou']:.4f}")
    print(f"Precision:          {overall_metrics['precision']:.4f}")
    print(f"Recall (Sensitivity): {overall_metrics['recall']:.4f}")
    print(f"Specificity:        {overall_metrics['specificity']:.4f}")
    print(f"F1 Score:           {overall_metrics['f1_score']:.4f}")
    print(f"Volume Error:       {overall_metrics['volume_error']:.4f}")
    print(f"Relative Vol Diff:  {overall_metrics['relative_volume_diff']:.4f}")
    
    if all_metrics:
        print(f"\nSLICE-LEVEL AVERAGE METRICS (åˆ‡ç‰‡çº§åˆ«å¹³å‡):")
        print(f"Avg Dice:           {avg_metrics['avg_dice']:.4f} Â± {avg_metrics['std_dice']:.4f}")
        print(f"Avg IoU:            {avg_metrics['avg_iou']:.4f} Â± {avg_metrics['std_iou']:.4f}")
        print(f"Avg Precision:      {avg_metrics['avg_precision']:.4f} Â± {avg_metrics['std_precision']:.4f}")
        print(f"Avg Recall:         {avg_metrics['avg_recall']:.4f} Â± {avg_metrics['std_recall']:.4f}")
    
    print(f"\nSTATISTICS:")
    print(f"Total slices:       {num_slices}")
    print(f"Slices with tumor:  {sum(1 for g in ground_truths if g.sum() > 0)}")
    print(f"Predicted tumors:   {sum(1 for p in predictions if p.sum() > 0)}")
    print(f"True tumor volume:  {sum(g.sum() for g in ground_truths)} voxels")
    print(f"Pred tumor volume:  {sum(p.sum() for p in predictions)} voxels")
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
    results_file = os.path.join(output_dir, f'{patient_id}_metrics.txt')
    with open(results_file, 'w') as f:
        f.write(f"EVALUATION RESULTS FOR PATIENT: {patient_id}\n")
        f.write("="*60 + "\n\n")
        
        f.write("OVERALL METRICS:\n")
        for key, value in overall_metrics.items():
            f.write(f"{key}: {value:.6f}\n")
        
        if all_metrics:
            f.write("\nSLICE-LEVEL METRICS:\n")
            for key, value in avg_metrics.items():
                f.write(f"{key}: {value:.6f}\n")
        
        f.write(f"\nDETAILED SLICE METRICS:\n")
        for metrics in all_metrics:
            f.write(f"Slice {metrics['slice_idx']}: Dice={metrics['dice']:.4f}, IoU={metrics['iou']:.4f}\n")
    
    print(f"\nDetailed results saved to: {results_file}")
    
    return predictions, overall_metrics, all_metrics

def test_on_nifti_file(model, fla_path, device, output_dir='compare_results'):
    """å¯¹NIfTIæ–‡ä»¶è¿›è¡Œæµ‹è¯•å¹¶ä¿å­˜ç»“æœï¼ˆæ— ground truthï¼‰"""
    # å¦‚æœè¾“å…¥è·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œåˆ™åŸºäºå½“å‰ç›®å½•æ„å»ºè·¯å¾„
    if not os.path.isabs(fla_path):
        fla_path = os.path.join(CURRENT_DIR, fla_path)
    
    # å¦‚æœè¾“å‡ºç›®å½•ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œåˆ™åŸºäºå½“å‰ç›®å½•æ„å»ºè·¯å¾„
    if not os.path.isabs(output_dir):
        output_dir = os.path.join(CURRENT_DIR, output_dir)
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    print(f"Loading NIfTI file from: {fla_path}")
    print(f"Output directory: {output_dir}")
    
    # åŠ è½½NIfTIæ–‡ä»¶
    fla_img = nib.load(fla_path)
    fla_data = fla_img.get_fdata()
    
    patient_id = os.path.basename(fla_path).replace('_fla.nii.gz', '')
    
    print(f"Processing patient: {patient_id}")
    print(f"Image shape: {fla_data.shape}")
    
    # å¯¹æ‰€æœ‰åˆ‡ç‰‡è¿›è¡Œé¢„æµ‹
    num_slices = fla_data.shape[2]
    predictions = []
    
    print("Processing slices...")
    with torch.no_grad():
        for slice_idx in range(num_slices):
            if (slice_idx + 1) % 20 == 0:
                print(f"  Processed {slice_idx + 1}/{num_slices} slices")
            
            # è·å–åˆ‡ç‰‡
            image_slice = fla_data[:, :, slice_idx]
            
            # è·³è¿‡ç©ºåˆ‡ç‰‡
            if image_slice.sum() == 0:
                predictions.append(np.zeros_like(image_slice))
                continue
            
            # é¢„å¤„ç†ï¼ˆä½¿ç”¨æ”¹è¿›çš„é¢„å¤„ç†æ–¹æ³•ï¼‰
            image_tensor = preprocess_image(image_slice).to(device)
            
            # é¢„æµ‹
            pred_mask = model(image_tensor)
            binary_mask = postprocess_mask(pred_mask)
            
            predictions.append(binary_mask)
            
            # ä¿å­˜ä¸€äº›ç¤ºä¾‹åˆ‡ç‰‡
            if slice_idx % 10 == 0 and binary_mask.sum() > 0:  # åªä¿å­˜æœ‰è‚¿ç˜¤çš„åˆ‡ç‰‡
                # å½’ä¸€åŒ–å›¾åƒç”¨äºæ˜¾ç¤º
                display_image = (image_slice - image_slice.min()) / (image_slice.max() - image_slice.min() + 1e-8)
                
                # å åŠ æ©ç 
                overlay_image = overlay_mask_on_image(display_image, binary_mask)
                
                # ä¿å­˜ç»“æœ
                plt.figure(figsize=(15, 5))
                
                plt.subplot(1, 3, 1)
                plt.imshow(display_image, cmap='gray')
                plt.title(f'Original Slice {slice_idx}')
                plt.axis('off')
                
                plt.subplot(1, 3, 2)
                plt.imshow(binary_mask, cmap='Reds')
                plt.title('Predicted Tumor Mask')
                plt.axis('off')
                
                plt.subplot(1, 3, 3)
                plt.imshow(overlay_image)
                plt.title('Overlay Result')
                plt.axis('off')
                
                plt.tight_layout()
                plt.savefig(f'{output_dir}/{patient_id}_slice_{slice_idx:03d}.png', dpi=150, bbox_inches='tight')
                plt.close()
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_tumor_voxels = sum(pred.sum() for pred in predictions)
    print(f"Total predicted tumor voxels: {total_tumor_voxels}")
    
    return predictions

def test_on_single_image(model, image_path, device, output_dir='compare_results'):
    """å¯¹å•å¼ å›¾åƒè¿›è¡Œæµ‹è¯•"""
    # å¦‚æœè¾“å…¥è·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œåˆ™åŸºäºå½“å‰ç›®å½•æ„å»ºè·¯å¾„
    if not os.path.isabs(image_path):
        image_path = os.path.join(CURRENT_DIR, image_path)
    
    # å¦‚æœè¾“å‡ºç›®å½•ä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œåˆ™åŸºäºå½“å‰ç›®å½•æ„å»ºè·¯å¾„
    if not os.path.isabs(output_dir):
        output_dir = os.path.join(CURRENT_DIR, output_dir)
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    print(f"Loading image from: {image_path}")
    print(f"Output directory: {output_dir}")
    
    # åŠ è½½å›¾åƒ
    if image_path.endswith('.nii.gz'):
        # NIfTIæ–‡ä»¶
        img = nib.load(image_path)
        image_data = img.get_fdata()
        if len(image_data.shape) == 3:
            image_data = image_data[:, :, image_data.shape[2]//2]  # å–ä¸­é—´åˆ‡ç‰‡
    else:
        # æ™®é€šå›¾åƒæ–‡ä»¶ - ä½¿ç”¨PILæ›¿ä»£cv2
        try:
            img = Image.open(image_path).convert('L')  # è½¬ä¸ºç°åº¦å›¾
            image_data = np.array(img, dtype=np.float32)
        except Exception as e:
            raise ValueError(f"Cannot load image: {image_path}. Error: {e}")
    
    # é¢„å¤„ç†ï¼ˆä½¿ç”¨æ”¹è¿›çš„é¢„å¤„ç†æ–¹æ³•ï¼‰
    image_tensor = preprocess_image(image_data).to(device)
    
    # é¢„æµ‹
    with torch.no_grad():
        pred_mask = model(image_tensor)
        binary_mask = postprocess_mask(pred_mask)
    
    # å½’ä¸€åŒ–å›¾åƒç”¨äºæ˜¾ç¤º
    display_image = (image_data - image_data.min()) / (image_data.max() - image_data.min() + 1e-8)
    
    # å åŠ æ©ç 
    overlay_image = overlay_mask_on_image(display_image, binary_mask)
    
    # æ˜¾ç¤ºå’Œä¿å­˜ç»“æœ
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.imshow(display_image, cmap='gray')
    plt.title('Original Image')
    plt.axis('off')
    
    plt.subplot(1, 3, 2)
    plt.imshow(binary_mask, cmap='Reds')
    plt.title('Predicted Tumor Mask')
    plt.axis('off')
    
    plt.subplot(1, 3, 3)
    plt.imshow(overlay_image)
    plt.title('Overlay Result')
    plt.axis('off')
    
    plt.tight_layout()
    
    # ä¿å­˜ç»“æœ
    output_filename = os.path.splitext(os.path.basename(image_path))[0] + '_result.png'
    output_path = os.path.join(output_dir, output_filename)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.show()
    
    print(f"Result saved to: {output_path}")
    
    return binary_mask, overlay_image

def main():
    parser = argparse.ArgumentParser(description='Brain Tumor Segmentation Comparison and Testing')
    parser.add_argument('--model_path', default='best_brain_tumor_model.pth', 
                       help='Path to trained model')
    parser.add_argument('--input_path', required=True,
                       help='Path to input image or NIfTI file')
    parser.add_argument('--ground_truth_path', default=None,
                       help='Path to ground truth segmentation file (optional)')
    parser.add_argument('--output_dir', default='compare_results',
                       help='Output directory for results (default: compare_results)')
    
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.isabs(args.output_dir):
        output_dir = os.path.join(CURRENT_DIR, args.output_dir)
    else:
        output_dir = args.output_dir
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Created output directory: {output_dir}")
    
    # åŠ è½½æ¨¡å‹
    try:
        model = load_model(args.model_path, device)
        print("âœ… Model loaded successfully!")
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æµ‹è¯•
    try:
        if args.input_path.endswith('_fla.nii.gz'):
            # NIfTIæ–‡ä»¶æµ‹è¯•
            if args.ground_truth_path:
                # æœ‰ground truthï¼Œè®¡ç®—å‡†ç¡®åº¦æŒ‡æ ‡
                predictions, metrics, slice_metrics = test_on_nifti_file_with_ground_truth(
                    model, args.input_path, args.ground_truth_path, device, args.output_dir)
                print(f"âœ… Results and metrics saved to {args.output_dir}")
            else:
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥è‡ªåŠ¨æ‰¾åˆ°å¯¹åº”çš„segæ–‡ä»¶
                auto_seg_path = args.input_path.replace('_fla.nii.gz', '_seg.nii.gz')
                if os.path.exists(auto_seg_path):
                    print(f"ğŸ” Found ground truth file: {auto_seg_path}")
                    predictions, metrics, slice_metrics = test_on_nifti_file_with_ground_truth(
                        model, args.input_path, auto_seg_path, device, args.output_dir)
                    print(f"âœ… Results and metrics saved to {args.output_dir}")
                else:
                    predictions = test_on_nifti_file(model, args.input_path, device, args.output_dir)
                    print(f"âœ… Results saved to {args.output_dir} (no ground truth available)")
        else:
            # å•å¼ å›¾åƒæµ‹è¯•
            mask, overlay = test_on_single_image(model, args.input_path, device, args.output_dir)
            print(f"âœ… Results saved to {args.output_dir}")
            
    except Exception as e:
        print(f"âŒ Error during testing: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œæä¾›é»˜è®¤æµ‹è¯•ç¤ºä¾‹
    import sys
    if len(sys.argv) == 1:
        # ç¤ºä¾‹ç”¨æ³•
        print("Brain Tumor Segmentation Model Comparison Tool")
        print("="*50)
        print("Usage examples:")
        print("  python compare.py --input_path path/to/patient_fla.nii.gz")
        print("  python compare.py --input_path path/to/patient_fla.nii.gz --ground_truth_path path/to/patient_seg.nii.gz")
        print("  python compare.py --input_path path/to/brain_image.png --model_path best_brain_tumor_model.pth")
        print("  python compare.py --input_path path/to/patient_fla.nii.gz --output_dir custom_compare_results")
        
        print(f"\nCurrent working directory: {CURRENT_DIR}")
        print("All relative paths will be resolved relative to this directory.")
        
        print(f"\nPyTorch version: {torch.__version__}")
        print("Required packages:")
        print("  pip install torch torchvision nibabel numpy matplotlib pillow scikit-learn")
        
        print("\nFeatures:")
        print("  âœ“ Compatible with PyTorch 2.6+ security changes")
        print("  âœ“ Automatic accuracy evaluation when ground truth is available")
        print("  âœ“ Comprehensive metrics: Dice, IoU, Precision, Recall, F1, Specificity")
        print("  âœ“ Visual comparison with color-coded overlays")
        print("  âœ“ Detailed results saved to text files")
        print("  âœ“ Improved preprocessing matching training pipeline")
        
        print("\nOutput:")
        print("  â†’ All results saved to 'compare_results' folder by default")
        print("  â†’ Comparison images with color-coded overlays")
        print("  â†’ Detailed metrics text files")
        print("  â†’ Individual slice visualizations")
        
        print("\nColor coding in comparison images:")
        print("  ğŸŸ¢ Green: True Positive (correctly predicted tumor)")
        print("  ğŸ”´ Red: False Positive (incorrectly predicted tumor)")
        print("  ğŸ”µ Blue: False Negative (missed tumor)")
    else:
        main()